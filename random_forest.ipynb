{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import datetime\n",
    "from scipy import stats\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, Xtr, Xte, ytr, yte, n_features=10, max_depth=8, min_size=1, sample_size=100, n_trees=50):\n",
    "        \n",
    "        self.Xtr = Xtr\n",
    "        self.Xte = Xte\n",
    "        self.ytr = ytr\n",
    "        self.yte = yte\n",
    "        self.n_features = n_features\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.sample_size = sample_size\n",
    "        self.n_trees = n_trees        \n",
    "        \n",
    "    # Split a dataset based on a feature and a threshold\n",
    "    def test_split(self, feature, threshold, group):\n",
    "        \n",
    "      \n",
    "        left1 = group[self.Xtr[group.astype(int),feature]<threshold]\n",
    "        right1 = group[np.logical_not(self.Xtr[group.astype(int),feature]<threshold)]\n",
    "        gini1 = self.gini_index((left1,right1))\n",
    "\n",
    "        return (left1, right1), gini1\n",
    "\n",
    "\n",
    "    # Calculate the Gini index for a split dataset\n",
    "    def gini_index(self, groups):\n",
    "        # count all samples at split point\n",
    "        n_instances = float(sum([len(group) for group in groups]))\n",
    "        # sum weighted Gini index for each group\n",
    "        gini = 0.0\n",
    "        for group in groups:\n",
    "            size = float(len(group))\n",
    "            # avoid divide by zero\n",
    "            if size == 0:\n",
    "                continue\n",
    "            score = 0.0\n",
    "            # score the group based on the score for each class\n",
    "            proportion_0 = sum(self.ytr[group.astype(int)]==[0])/size\n",
    "    #         print(proportion_0)\n",
    "            score += proportion_0**2\n",
    "            proportion_1 = sum(self.ytr[group.astype(int)]==[1])/size\n",
    "    #         print(proportion_1)\n",
    "            score += proportion_1**2\n",
    "\n",
    "            # weight the group score by its relative size\n",
    "            gini += (1.0 - score) * (size / n_instances)\n",
    "        return gini\n",
    "\n",
    "    # Select the best split point for a dataset\n",
    "    def find_split(self,group):\n",
    "        b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "        features = np.random.choice(self.Xtr.shape[1], self.n_features, replace=True)\n",
    "        for feature in features:\n",
    "            for row_idx in group:\n",
    "                groups, gini = self.test_split(feature, self.Xtr[row_idx.astype(int),feature.astype(int)],group)\n",
    "    #             gini = gini_index(groups, class_values)\n",
    "                if gini < b_score:\n",
    "                    b_index, b_value, b_score, b_groups = feature, self.Xtr[row_idx.astype(int),feature.astype(int)], gini, groups\n",
    "        f_sig[b_index] += len(groups[0])+len(groups[1]) \n",
    "\n",
    "        return {'index':b_index, 'value':b_value, 'groups':b_groups}\n",
    "\n",
    "\n",
    "    # Create a terminal node value\n",
    "    def to_terminal(self, group):\n",
    "#         print('to terminal', type(self.ytr[group]))\n",
    "        return stats.mode(self.ytr[group.astype(int)])[0]\n",
    "\n",
    "    # Create child splits for a node or make terminal\n",
    "    def split(self, node, depth):\n",
    "\n",
    "        left, right = node['groups']\n",
    "        del(node['groups'])\n",
    "        \n",
    "        # check for a no split\n",
    "        if len(left)==0 or len(right)==0:\n",
    "            node['left'] = node['right'] = self.to_terminal(np.hstack((left,right)))\n",
    "            return\n",
    "        \n",
    "        # check for max depth\n",
    "        if depth >= self.max_depth:\n",
    "            node['left'], node['right'] = self.to_terminal(left), self.to_terminal(right)\n",
    "            return\n",
    "        \n",
    "        # process left child\n",
    "        if len(left) <= self.min_size:\n",
    "            node['left'] = self.to_terminal(left)\n",
    "        else:\n",
    "            node['left'] = self.find_split(left)\n",
    "            self.split(node['left'],depth+1)\n",
    "\n",
    "        # process right child\n",
    "        if len(right) <= self.min_size:\n",
    "            node['right'] = self.to_terminal(right)\n",
    "        else:\n",
    "            node['right'] = self.find_split(right)\n",
    "            self.split(node['right'], depth+1)\n",
    "\n",
    "\n",
    "    # Build a decision tree\n",
    "    def build_tree(self):\n",
    "        root = self.find_split(self.sample_idx)\n",
    "        self.split(root, 1)\n",
    "        return root\n",
    "\n",
    "    # Make a prediction with a decision tree\n",
    "    def predict(self, node, row):\n",
    "\n",
    "        if row[node['index']] < node['value']:\n",
    "            if isinstance(node['left'], dict):\n",
    "                return self.predict(node['left'], row)\n",
    "            else:\n",
    "                return node['left']\n",
    "        else:\n",
    "            if isinstance(node['right'], dict):\n",
    "                return self.predict(node['right'], row)\n",
    "            else:\n",
    "                return node['right']\n",
    "\n",
    "    # Make a prediction with a list of bagged trees\n",
    "    def bagging_predict(self, trees, row):\n",
    "        predictions = np.array([])\n",
    "        for tree in trees:\n",
    "            predictions = np.hstack((predictions,self.predict(tree, row)))\n",
    "        return stats.mode(predictions)[0]\n",
    "\n",
    "    # Random Forest Algorithm\n",
    "    def random_forest(self):\n",
    "        trees = list()\n",
    "        for i in range(self.n_trees):\n",
    "            self.sample_idx = np.random.choice(self.Xtr.shape[0], self.sample_size, replace=True)\n",
    "            tree = self.build_tree()\n",
    "            trees.append(tree)\n",
    "            print('Tree: ',i)\n",
    "            startDT = datetime.datetime.now()\n",
    "            print (str(startDT))\n",
    "        predictions = [self.bagging_predict(trees, row) for row in self.Xte]\n",
    "        return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
